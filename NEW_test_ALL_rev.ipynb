{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a80c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sent2vec.vectorizer import Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b7748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"这是一本学习 NLP 的好书\",\n",
    "    \"DistilBERT 是一个了不起的 NLP 模型\",\n",
    "    \"我们可以交替使用嵌入、编码或矢量化。\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc72bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9d7ff7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer(pretrained_weights=\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abb402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.run(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fcc87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e709963e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc4c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences = [\n",
    "    \"This is an awesome book to learn NLP.\",\n",
    "    \"DistilBERT is an amazing NLP model.\",\n",
    "    \"We can interchangeably use embedding, encoding, or vectorizing.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be9ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.run(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8a1d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3bed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"This is an awesome book to learn NLP.\",\n",
    "    \"DistilBERT is an amazing NLP model.\",\n",
    "    \"We can interchangeably use embedding, encoding, or vectorizing.\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9f6ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b81f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.run(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d146d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorizer.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d36f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "dist_1 = spatial.distance.cosine(vectors[0], vectors[1])\n",
    "dist_2 = spatial.distance.cosine(vectors[0], vectors[2])\n",
    "print('dist_1: {0}, dist_2: {1}'.format(dist_1, dist_2))\n",
    "assert dist_1 < dist_2\n",
    "# dist_1: 0.043, dist_2: 0.192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e42ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = '~/gensim-data/glove.6B.300d.txt'\n",
    "word2vec_glove_file = get_tmpfile(\"glove.6B.300d.word2vec.txt\")\n",
    "glove2word2vec(glove_file, word2vec_glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64682a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer(pretrained_weights= word2vec_glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26232beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "newer_sentences = [\n",
    "    \"Alice is in the Wonderland.\",\n",
    "    \"Alice is not in the Wonderland.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a4cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.run(newer_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fda0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f775a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d6f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.run(newer_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d786c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc37268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorizer.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda48e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "dist_1 = spatial.distance.cosine(vectors[0], vectors[1])\n",
    "print('dist_1: {0}'.format(dist_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f326635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sent2vec.constants import PRETRAINED_VECTORS_PATH_WIKI, ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2a1757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing word2vec with vector path ~\\gensim-data/glove-wiki-gigaword-300\\glove-wiki-gigaword-300.gz\n"
     ]
    }
   ],
   "source": [
    "vectorizer = Vectorizer(pretrained_weights= PRETRAINED_VECTORS_PATH_WIKI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b017bd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.run(newer_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cb03d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.run(newer_sentences, remove_stop_words=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18cdf882",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorizer.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30c16d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "dist_1 = spatial.distance.cosine(vectors[0], vectors[1])\n",
    "#dist_2 = spatial.distance.cosine(vectors[1], vectors[3])\n",
    "#print('dist_1: {0}, dist_2: {1}'.format(dist_1, dist_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe5adf61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c763f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.vocab['not'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97491165",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['not'].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755cab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['not'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc9bdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dist_1 == dist_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe5fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sent2vec.splitter import *\n",
    "\n",
    "newer_sentences = [\n",
    "    \"Alice is in the Wonderland.\",\n",
    "    \"Alice is not in the Wonderland.\",\n",
    "]\n",
    "\n",
    "splitter = Splitter()\n",
    "\n",
    "splitter.sent2words(newer_sentences, remove_stop_words = [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de545d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0400edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.vocab['not'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2121c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stop_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1064bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in remove_stop_words:\n",
    "    nlp.vocab[w].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['not'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1708e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for sentence in newer_sentences:\n",
    "    doc = nlp(sentence.lower())\n",
    "    words.append([token.lemma_ for token in doc if not token.is_punct | token.is_space | token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21207d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
